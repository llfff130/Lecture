# 讲座5笔记
## 大纲  
- OpenMP 同步构造
    - 临界区、原子操作和屏障
- 数据依赖
    - 指令级数据依赖
    - 循环携带数据依赖
- 归约操作
- OpenMP 归约子句
- 练习：归约操作
- 扫描（或前缀）操作
- 作业 3
## 1. OpenMP同步结构
- **关键区域（Critical）**：确保同一时间只有一个线程执行该区域，防止竞态条件。临界区指令必须在并行区域内
  ```c
  #pragma omp critical
  count++;
  ```
  
- **原子操作（Atomic）**：仅适用于单个内存位置的更新，提供互斥保护。原子指令仅适用于其后紧跟的语句
  ```c
  #pragma omp atomic
  sum += lsum;
  ```
  
- **屏障（Barrier）**：所有线程必须到达屏障点后才能继续执行。在 OpenMP 中，大多数构造在构造结束时都有一个隐含的障碍
    - 要移除该障碍，使用 nowait 子句
  ```c
  #pragma omp barrier
  ```

## 2. 数据依赖
- **指令级数据依赖**：
  - **流依赖（RAW）**：真实依赖，必须按顺序执行。
  - **反依赖（WAR）**和**输出依赖（WAW）**：可通过变量重命名消除。

- **循环携带依赖**：
  - 检查循环迭代间是否存在依赖关系，若无依赖则可并行化。
  - 数据竞争:`一个线程写入而另一个线程读取相同的数据`
  - 示例：
    ```c
    for (i=0; i<n; i++) {
        a[i] = b[i] + e[i];
        d[i] = e * a[i+1];
    }
    ```
    - 一般来说，我们需要关注以下循环携带数据依赖关系：
        1. 数组数据的索引不等于当前循环索引
        2. 变量的值随迭代变化
    可通过拆分循环或调整指令顺序消除依赖。

## 3. 归约操作
- **问题**：计算数组元素的和（或其他关联操作）。
- **并行化方法**：
  - **OpenMP归约子句**：
    ```c
    #pragma omp parallel for reduction(+:S)
    for (i=0; i<n; i++) S += a[i];
    ```
  - **手动实现**：每个线程计算部分和，再累加结果。
  ```c
    #pragma omp parallel shared(a,S) private(i) 
    {
        double lsum = 0.0; //每个线程都有一个局部 lsum 变量
        #pragma omp for nowait
        for (i=0; i<n; i++) //迭代次数分配 
            lsum +=  a[i];    //每个线程计算一个局部和
        ⋯ //累加局部和
    }
  ```
- `归约子句`
| 运算符 | 初始值  | 运算符 | 初始值 |
| --- | ---- | --- | --- |
| +   | 0    | &&  | 1   |
| \*  | 1    | &   | ~0  |
| -   | 0    | ^   | 0   |
| min | 最大正数 | >   | 0   |
| max | 最小负数 | 异或  | 0   |

```bash
实验：归约操作
编写一个 OpenMP 程序来计算 𝑛𝑛 个数的和
你需要编写两个例程：
一个使用 OpenMP 归约子句
另一个是让每个线程计算一个局部和，然后累加局部和
运行你的程序来比较这两个例程的性能
```

## 4. 扫描（前缀）操作
- **问题**：计算数组的前缀和（如`[1, 3, 6, 10, ...]`）。
- **并行算法**：
  1. **阶段1**：每个线程计算局部前缀和，保存最后一个元素到共享数组。
  2. **阶段2**：单线程计算共享数组的前缀和。
  3. **阶段3**：每个线程将共享数组的值加到局部结果中。
- **操作总数**：约`2n`，比串行算法多一倍，但并行时间更短。

## 5. 作业3：并行扫描操作
- 实现上述并行扫描算法，并与串行算法比较性能。
- **单线程区域**：使用`#pragma omp single`确保部分代码仅由一个线程执行。

## 关键点总结
- **同步**：保护共享数据，避免竞态条件。
- **依赖分析**：确保并行化的正确性。
- **归约与扫描**：利用关联操作特性设计高效并行算法。


